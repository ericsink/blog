---
layout: default
esbma_id: 1627
title: Advocating the use of code coverage
date: 2006-09-12 21:50:43
keywords: (dev)
---
<p><img width=251 height=146 src="/scm/1627_image001.gif"
align=right hspace=12>I am somewhat fanatical about unit testing and code
coverage.&nbsp; The screen dumps to the right show the most recent results from
running the unit tests in the core library of my hobby project [footnote: sd].&nbsp;
As you can see, all my unit tests are passing and my code coverage right now is
100%.&nbsp; This library consists of 12,341 lines of algorithms, plus 5,819 lines of
unit tests.</p>

<p><img width=250 height=736 src="/scm/1627_image002.gif"
align=right hspace=12>And yes, I'm feeling rather smug about my code coverage
being at 100%.&nbsp; <b>:-)</b></p>

<p>Code coverage is a controversial subject.&nbsp; Gurus have been
debating the related issues for decades.&nbsp; I won't pretend to be one of those
experts, but I see no reason not to pass along a few thoughts from my own
experience in this area.</p>

<h3>What is code coverage?</h3>

<p>A code coverage tool simply keeps track of which parts of
your code get executed and which parts do not.</p>

<p>Usually, the results are granular down to the level of each
line of code.&nbsp; So in a typical situation, you launch your application with a
code coverage tool configured to monitor it.&nbsp; When you exit the application,
the tool will produce a code coverage report which shows which lines of code
were executed and which ones were not.&nbsp; If you count the total number of lines
which were executed and divide by the total number of lines which could have
been executed, you get a percentage.&nbsp; If you believe in code coverage, the
higher the percentage, the better.&nbsp; In practice, reaching 100% is extremely
rare.</p>

<p>Did I mention how smug I'm feeling?&nbsp; <b>:-)</b></p>

<p>The use of a code coverage tool is usually combined with the
use of some kind of automated test suite.&nbsp; Without automated testing, a code
coverage tool merely tells you which features a human user remembered to use.&nbsp;
Such a tool is far more useful when it is measuring how complete your test
suite is with respect to the code you have written.</p>

<h3>What should the coverage goal be?</h3>

<p>Some folks would say that a goal of 100% coverage is
pathological.&nbsp; They have a point.</p>

<p>As you write more and more tests and your coverage number
gets higher and higher, you start experiencing the law of diminishing returns.&nbsp;
Those last few percentage points are tough to hit.&nbsp; It can take a lot of effort
to come up with enough unit tests to get all the way to 100 percent.&nbsp; Lots of
successful projects have been done with test suites that cover only 85-95 percent
of the code. [footnote: none]</p>

<p>Others would argue that the goal should always be <a
href="http://homepage.mac.com/hey.you/lessons.html">100% coverage and no less</a>.&nbsp;
Personally, I would stop short of such a recommendation, but for this
particular project of mine, getting full coverage has been worth the effort.</p>

<h3>Raising the percentage</h3>

<p>How did I get to 100%?</p>

<p>First, let me give credit to the fine tools I've been using:</p>

<ul style='margin-top:0in' type=disc>
 <li >For my unit tests, I am using <a href="http://nunit.org/">NUnit</a>.</li>
 <li >For measuring code coverage, I am using <a
     href="http://www.ncover.org/">NCover</a>.</li>
 <li >For viewing the results, I am using <a
     href="http://www.kiwidude.com/blog/index.html">NCoverExplorer</a>.</li>
 <li >For integrating all these things with Visual Studio 2005,
     I am using <a href="http://www.testdriven.net/">TestDriven.NET</a>.</li>
</ul>

<p>The truth is that 100% coverage was not my goal.&nbsp; I have
generally tried to keep the percentage anywhere above 95.&nbsp; But every so often I
would just add another unit test when I didn't feel like coding a new feature.&nbsp;
When I got to 99%, I started wondering what it would take to get all the way to
100.</p>

<p>Whatever your goal, the basic technique for increasing your
code coverage isn't rocket science.&nbsp; Here's what I did:</p>

<ul style='margin-top:0in' type=disc>
 <li >Look at some code which is not being tested.</li>
 <li >Think about how to reach that code.</li>
 <li >If the code can be reached, write a test case to make it
     happen.</li>
 <li >If the code can never actually be reached, then it's not
     needed.&nbsp; Remove the code and put in some kind of an assertion to make sure.</li>
</ul>

<p>Repeat these steps until your coverage level is where you
want it to be.</p>

<h3>Forced code reviews</h3>

<p>One of my favorite things about code coverage is that it
forces you to look at your code.&nbsp; All too often we write code and nothing but a
compiler ever looks at it again.</p>

<p>In fact, were I to argue that everyone should have 100% code
coverage as their goal, I would build my argument on two main points:</p>

<p style='margin-left:.25in;text-indent:-.25in'>1.<span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>Getting
your code coverage to 100% will force you to review the parts of your code
which probably need to be looked at.</p>

<p style='margin-left:.25in;text-indent:-.25in'>2.<span
style='font:7.0pt "Times New Roman"'>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span>If
you just can't find a way to get your coverage to 100%, there's a good chance
that the uncovered part of your code is simply wrong in some way.</p>

<p>I'm too much of a pragmatist to make that argument, but it
tempts me.&nbsp; <b>:-)</b></p>

<p>In my case, code coverage forced me to look at my code and realize
that some of my coding practices weren't very smart.&nbsp; For example, consider the
following snippet:</p>

<p><span style='font-size:9.0pt;font-family:"Courier New"'>if
(condition1)<br>
{<br>
&nbsp; return result1;<br>
}<br>
else if (condition2)<br>
{<br>
&nbsp; return result2;<br>
}<br>
else if (condition3)<br>
{<br>
&nbsp; return result3;<br>
}</span></p>

<p>In this case, suppose that I know for certain that one of
the three conditions (condition1, condition2 or condition3) must be true.&nbsp; It should
be impossible for the code to fall through all three of these if statements.&nbsp;
Unfortunately, my C# compiler doesn't know that, and it gripes about the fact
that not all code paths return a value.&nbsp; So I append the following:</p>

<p><span style='font-size:9.0pt;font-family:"Courier New"'>else<br>
{<br>
&nbsp; throw new Exception("Should Never Happen");<br>
}</span></p>

<p>Now the compiler is happy, but my code coverage tool is
not.&nbsp; Unsurprisingly, the line which contains the string "Should Never Happen"
never actually gets executed.</p>

<p>Throwing an exception isn't really the best way to handle a
situation which should <i>never</i> happen.&nbsp; That's what assertions are for:</p>

<p><span style='font-size:9.0pt;font-family:"Courier New"'>if
(condition1)<br>
{<br>
&nbsp; return result1;<br>
}<br>
else if (condition2)<br>
{<br>
&nbsp;&nbsp;return result2;<br>
}<br>
else<br>
{<br>
&nbsp; Debug.Assert(condition3);<br>
&nbsp; return result3;<br>
}</span></p>

<p>Instead of checking for condition3 explicitly with an if
statement, I simply assume that condition3 must be true when both condition1
and condition2 were found to be false.&nbsp; And to be safe, I throw in a
Debug.Assert so in my non-release builds I will get a big ugly dialog box if
the unthinkable happens and all three conditions are actually false.</p>

<p>Now I can get full code coverage of this snippet by simply
writing unit tests which cause all three conditions to happen.</p>

<p>But increased code coverage of this snippet is not the only
result of my efforts.&nbsp; The other good news is that my revised snippet is simply
better.&nbsp; It is smaller and faster. [footnote: perf]</p>

<h3>Regression testing</h3>

<p>Code coverage and automated testing go hand-in-hand.&nbsp; In my
experience, the most important benefit I have gained from applying these
disciplines together is regression testing.</p>

<p>Regression testing is simply the act of testing to see if
your code somehow got broken.&nbsp; The code used to work, but now it doesn't.&nbsp; It
has regressed.&nbsp; When this lamentable situation happens, we want to know about
it as quickly as possible.</p>

<p>All experienced developers know that even though every code
change is well-intentioned, every code change carries the <a
href="/articles/Four_Questions.html">risk</a> of consequences
that were not intended.&nbsp; Code tends to get brittle, and then it breaks when we
try to bend it.</p>

<p>I cannot imagine trying to build a solid modeling engine
without a comprehensive suite of automated tests.&nbsp; For example, one of the most
troublesome areas of my project is performing intersection operations on 3D
objects.&nbsp; When my app wants to drill a hole in a board, it constructs a
cylinder, positions it inside the board, and performs a "subtract" operation.&nbsp; In
getting this code to work, I have seen a seemingly endless stream of special
cases.&nbsp; Very often when I fixed the code to handle a new situation, it broke
something that was previously working just fine.&nbsp; Without unit tests and code
coverage to tell me when my code regressed, I suspect I would simply churn
forever in an endless game of whack-a-mole.</p>

<h3>Different circumstances</h3>

<p>I suspect that now at least one of my readers is asking, "How
can automated testing and code coverage possibly be important when neither of
them is mentioned on <a
href="http://www.joelonsoftware.com/articles/fog0000000043.html">The Joel Test</a>?"&nbsp;
<b>:-)</b></p>

<p>I'll admit that automated testing and code coverage are more
important for some projects than for others.&nbsp; My library of computational
geometry algorithms is a natural place to apply code coverage and automated
testing.&nbsp; Most of my test cases are very straightforward.</p>

<ul style='margin-top:0in' type=disc>
 <li >Create a 3D model of a 5-inch cube.&nbsp; </li>
 <li >Verify that the volume is 125 cubic inches.&nbsp; </li>
 <li >Create a model of a 3-inch cube.&nbsp; </li>
 <li >Subtract it from the other one.&nbsp; </li>
 <li >Verify that the resulting model's volume is 98 cubic
     inches.&nbsp; </li>
</ul>

<p>These are algorithms.&nbsp; They don't really have any outside
dependencies.&nbsp; They are either correct or they are not.&nbsp; External dependencies
and oddball technologies make automated testing harder:</p>

<ul style='margin-top:0in' type=disc>
 <li >I am currently not testing the GUI sections of my code, so
     I don't have to complain about TestComplete not having WPF support yet [footnote:
     aqa].&nbsp; </li>
 <li >My library doesn't use networking or I/O of any kind, so I
     don't have to deal with setting up servers.&nbsp; </li>
 <li >My code is all C#, so NCover just works well for me and I
     don't have to wonder if there are any code coverage tools for T-SQL or
     VBA.</li>
</ul>

<p>So I acknowledge that code coverage will not fit all
scenarios quite as nicely as it fits mine.&nbsp; If code coverage deserves to be on
the Joel Test, it is certainly less deserving than something like source
control.&nbsp; I can imagine a situation where a smart team might choose not to do
code coverage.&nbsp; I cannot picture any team that chooses not to use source
control without thinking of them all as clueless bozos.</p>

<p>Still, I believe that most of the time, anything you invest
in automated testing will produce worthwhile returns. [footnote: invest]</p>

<h3>Fooling yourself</h3>

<p>Every now and then, I meet somebody who thinks that a body
of code is perfect if its unit tests all pass with 100% code coverage.&nbsp; This
obviously isn't true.&nbsp; Code coverage can only tell you how much of your code is
being tested.&nbsp; It cannot tell you how much code you still need to write.</p>

<p>And in turn, some folks think that because 100% code
coverage cannot be understood to mean 100% correctness, then code coverage
isn't worth anything at all.&nbsp; To me, that's like saying we should never talk
about the temperature outside because by itself it is not a reliable way of
determining how nice the weather is.</p>

<p>Unit testing and code coverage are tools.&nbsp; They provide us a
way of increasing the quality of our code, but 100% code coverage certainly
does not mean 100% code quality.&nbsp; If you want a complete QA effort, one which
offers you high confidence that your code is reliably doing whatever you want
it to do, then unit testing and code coverage are just a small part of the
story.&nbsp; There are many other tools and techniques you should consider.</p>

<h3>Covering without testing</h3>

<p>For some parts of my code, I was diligent.&nbsp; I wrote unit
tests that were deliberately designed to exercise all the cases I could think
of.&nbsp; For example, I have some code that calculates the intersection of two 2D
polygons.&nbsp; One of my unit tests for this code contains a bunch of different
situations involving two rectangles:</p>

<ul style='margin-top:0in' type=disc>
 <li >Two rectangles that are far apart</li>
 <li >Two rectangles that share an edge</li>
 <li >Two rectangles that share a vertex</li>
 <li >Two rectangles that intersect with no overlapping edges
     and no shared vertices</li>
 <li >Two rectangles, one inside the other, sharing part of an
     edge</li>
 <li >Two rectangles, one inside the other, sharing part of two
     edges</li>
 <li >Two rectangles, one inside the other, sharing part of
     three edges</li>
 <li >Two rectangles that are really the same rectangle</li>
 <li >Two rectangles, one inside the other, but they don't touch</li>
</ul>

<p>In this situation and several others like it, I practiced <a
href="http://en.wikipedia.org/wiki/Test_driven_development">Test Driven
Development</a>.&nbsp; I wrote the test cases first and then I wrote the
implementation and worked on it until all the tests were green.</p>

<p>But I'll confess that in other situations, I am not always
so thorough.&nbsp; Sometimes I write a unit test that does nothing but force some
code to be executed with one simple case.&nbsp; This makes my code coverage number
look good, but it doesn't really test my code very well.</p>

<p>For example, I have a method that takes a solid model and
produces the data structures necessary for creating an animated display.&nbsp; In my
unit tests I call this method only once.&nbsp; This method isn't really being
exercised.&nbsp; The edge cases aren't being explored.&nbsp; I haven't written any
abusive unit tests which try to cause this method to fail.</p>

<p>This trick is something I call "covering without testing".&nbsp;
It's better than nothing, since I do gain the benefits of some regression
testing on that method.&nbsp; But obviously the coverage is thicker in some places
than in others.</p>

<p>My code coverage is 100%, but the truth is that this
particular method might be robust, or it might not.&nbsp; I don't really know.</p>

<h3>And if you thought that example was bad...</h3>

<p>My code coverage is 100%, but there are even worse skeletons
in my closet.&nbsp; Specifically, I know of one piece of code which is definitely
not robust.&nbsp; Furthermore, it's probably an order of magnitude slower than it
needs to be.</p>

<p>For the rest of this particular story, see my guest entry
over on <a href="http://thedailywtf.com/forums/thread/91407.aspx">The Daily WTF</a>
which ran on 14 September 2006. &nbsp;Alex Papadimoulis was on vacation.&nbsp; I was
honored that he asked me to be guest editor for a day, so I wrote up something
on a piece of my computational geometry code which is really quite heinous.</p>

<p>But hey, my code coverage is 100%, right?&nbsp; <b>:-)</b></p>

<h3>Bottom Line</h3>

<p>Like I said, I am somewhat fanatical about automated testing
and code coverage.&nbsp; I enthusiastically recommend using them.</p>

<p>But use them wisely.&nbsp; Testing guru Brian Marick said it
best:&nbsp; Code coverage tools are "only helpful if they're used to <i>enhance </i>thought,
not <i>replace </i>it" (<a href="http://www.testing.com/writings/coverage.pdf">PDF</a>).</p>

<h3>Footnotes</h3>

<p style='margin-left:.75in;text-indent:-.75in'>[sd]&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; My
hobby project is a solid modeling application for woodworkers.&nbsp; Sorry, I'm not
ready for anybody else to see it yet.</p>

<p style='margin-left:.75in;text-indent:-.75in'>[none]&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Heck,
lots of successful projects have been done with no code coverage discipline at
all.&nbsp; That doesn't mean the category needs more entries.</p>

<p style='margin-left:.75in;text-indent:-.75in'>[perf]&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; If
you are inclined to argue my claim that the code is faster, consider the
possibility that it might be quite expensive to check condition3.</p>

<p style='margin-left:.75in;text-indent:-.75in'>[aqa]&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; To
Drew Wells at <a href="http://www.automatedqa.com/">AutomatedQA</a>:&nbsp; You guys <i>are</i>
going to support WPF someday, right?&nbsp; <b>;-)</b></p>

<p style='margin-left:.75in;text-indent:-.75in'>[invest]&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; I
chose carefully when I used the word "invest".&nbsp; The truth is that it is not
trivial to build a really good automated testing suite. &nbsp;I have written 5,819
lines of code which don't do anything at all.&nbsp; Almost one third of my code adds
no functionality to my app.</p>

<p></p>
